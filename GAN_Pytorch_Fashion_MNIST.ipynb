{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SisekoC/My-Notebooks/blob/main/GAN_Pytorch_Fashion_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Nln2VA_bjYsy"
      },
      "outputs": [],
      "source": [
        "!mkdir diff-run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "D54v_DF0jakG"
      },
      "outputs": [],
      "source": [
        "!mkdir diff-run/images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yoj6U2rmjiS-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "from torchvision.utils import save_image\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchsummary import summary\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-S2ZtWdajpz3",
        "outputId": "05922ec2-a1e9-4f0c-b5bb-414cb3798a57"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7e5bc82bc2b0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "torch.manual_seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "56IrzS6xmqTk"
      },
      "outputs": [],
      "source": [
        "writer = SummaryWriter('diff-run/py-gan')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xVXC_q2ekuf8"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "batch_size = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rmKRUtX6kwt1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39e7d19c-449b-4f8b-81a2-b516f461c535"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:08<00:00, 2956940.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 200453.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:03<00:00, 1443285.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 6169222.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5], [0.5])])\n",
        "train_dataset = datasets.FashionMNIST(root='./data/', train=True, transform=train_transform, download=True)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0ImLVM7lk2du"
      },
      "outputs": [],
      "source": [
        "image_shape = (1, 28, 28)\n",
        "image_dim = int(np.prod(image_shape))\n",
        "latent_dim = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_gw3SMN7jtOB"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(nn.Linear(latent_dim, 128),\n",
        "                                    nn.LeakyReLU(0.2, inplace=True),\n",
        "                                    nn.Linear(128, 256),\n",
        "                      nn.BatchNorm1d(256, 0.8),\n",
        "                                    nn.LeakyReLU(0.2, inplace=True),\n",
        "                                    nn.Linear(256, 512),\n",
        "                      nn.BatchNorm1d(512, 0.8),\n",
        "                                    nn.LeakyReLU(0.2, inplace=True),\n",
        "                      nn.Linear(512, 1024),\n",
        "                      nn.BatchNorm1d(1024, 0.8),\n",
        "                                    nn.LeakyReLU(0.2, inplace=True),\n",
        "                                    nn.Linear(1024, image_dim),\n",
        "                                    nn.Tanh())\n",
        "\n",
        "    def forward(self, noise_vector):\n",
        "        image = self.model(noise_vector)\n",
        "        image = image.view(image.size(0), *image_shape)\n",
        "        return image\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xPEMXbaJCPsQ"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(nn.Linear(image_dim, 512),\n",
        "                                    nn.LeakyReLU(0.2, inplace=True),\n",
        "                                    nn.Linear(512, 256),\n",
        "                                    nn.LeakyReLU(0.2, inplace=True),\n",
        "                                    nn.Linear(256, 1),\n",
        "                                    nn.Sigmoid())\n",
        "\n",
        "    def forward(self, image):\n",
        "        image_flattened = image.view(image.size(0), -1)\n",
        "        result = self.model(image_flattened)\n",
        "        return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1HJv-CnSkIuN"
      },
      "outputs": [],
      "source": [
        "generator = Generator().to(device)\n",
        "discriminator = Discriminator().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "9RluLBy9t_7X"
      },
      "outputs": [],
      "source": [
        "torch.save(generator.state_dict(), 'generator.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "DP2GVHfYFdQt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "801b1bf1-ef49-4e72-e089-f91edab7ff8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method Module.type of Sequential(\n",
            "  (0): Linear(in_features=100, out_features=128, bias=True)\n",
            "  (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  (2): Linear(in_features=128, out_features=256, bias=True)\n",
            "  (3): BatchNorm1d(256, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  (5): Linear(in_features=256, out_features=512, bias=True)\n",
            "  (6): BatchNorm1d(512, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  (8): Linear(in_features=512, out_features=1024, bias=True)\n",
            "  (9): BatchNorm1d(1024, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  (11): Linear(in_features=1024, out_features=784, bias=True)\n",
            "  (12): Tanh()\n",
            ")>\n"
          ]
        }
      ],
      "source": [
        " for layer in generator.children():\n",
        "     print(layer.type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-3o5-nqM_m3",
        "outputId": "e171bd6e-8efd-4a41-a2c7-22572db36cd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                  [-1, 128]          12,928\n",
            "         LeakyReLU-2                  [-1, 128]               0\n",
            "            Linear-3                  [-1, 256]          33,024\n",
            "       BatchNorm1d-4                  [-1, 256]             512\n",
            "         LeakyReLU-5                  [-1, 256]               0\n",
            "            Linear-6                  [-1, 512]         131,584\n",
            "       BatchNorm1d-7                  [-1, 512]           1,024\n",
            "         LeakyReLU-8                  [-1, 512]               0\n",
            "            Linear-9                 [-1, 1024]         525,312\n",
            "      BatchNorm1d-10                 [-1, 1024]           2,048\n",
            "        LeakyReLU-11                 [-1, 1024]               0\n",
            "           Linear-12                  [-1, 784]         803,600\n",
            "             Tanh-13                  [-1, 784]               0\n",
            "================================================================\n",
            "Total params: 1,510,032\n",
            "Trainable params: 1,510,032\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.05\n",
            "Params size (MB): 5.76\n",
            "Estimated Total Size (MB): 5.82\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "summary(generator, (100,))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdNrhNT7NcQ4",
        "outputId": "e467acaf-e673-432e-a1d0-a2faf79970c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                  [-1, 512]         401,920\n",
            "         LeakyReLU-2                  [-1, 512]               0\n",
            "            Linear-3                  [-1, 256]         131,328\n",
            "         LeakyReLU-4                  [-1, 256]               0\n",
            "            Linear-5                    [-1, 1]             257\n",
            "           Sigmoid-6                    [-1, 1]               0\n",
            "================================================================\n",
            "Total params: 533,505\n",
            "Trainable params: 533,505\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.01\n",
            "Params size (MB): 2.04\n",
            "Estimated Total Size (MB): 2.05\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "summary(discriminator, (1,28,28))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "RFxQC7T0laZi"
      },
      "outputs": [],
      "source": [
        "adversarial_loss = nn.BCELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "sis4zEVQkLf_"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.0002\n",
        "G_optimizer = optim.Adam(generator.parameters(), lr = learning_rate, betas=(0.5, 0.999))\n",
        "D_optimizer = optim.Adam(discriminator.parameters(), lr = learning_rate, betas=(0.5, 0.999))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "mWjUcjslt_2F"
      },
      "outputs": [],
      "source": [
        "cuda = True if torch.cuda.is_available() else False\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "LQLFEfpgkLjS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c140d30a-7137-41b8-c336-791e1b1ac0d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [1/500]: D_loss: 1.038, G_loss: 1.310\n",
            "Epoch: [2/500]: D_loss: 0.868, G_loss: 2.099\n",
            "Epoch: [3/500]: D_loss: 1.023, G_loss: 1.740\n",
            "Epoch: [4/500]: D_loss: 1.064, G_loss: 1.570\n",
            "Epoch: [5/500]: D_loss: 1.095, G_loss: 1.438\n",
            "Epoch: [6/500]: D_loss: 1.118, G_loss: 1.392\n",
            "Epoch: [7/500]: D_loss: 1.116, G_loss: 1.362\n",
            "Epoch: [8/500]: D_loss: 1.089, G_loss: 1.477\n",
            "Epoch: [9/500]: D_loss: 1.076, G_loss: 1.469\n",
            "Epoch: [10/500]: D_loss: 1.096, G_loss: 1.383\n",
            "Epoch: [11/500]: D_loss: 1.107, G_loss: 1.400\n",
            "Epoch: [12/500]: D_loss: 1.119, G_loss: 1.358\n",
            "Epoch: [13/500]: D_loss: 1.161, G_loss: 1.269\n",
            "Epoch: [14/500]: D_loss: 1.147, G_loss: 1.250\n",
            "Epoch: [15/500]: D_loss: 1.159, G_loss: 1.239\n",
            "Epoch: [16/500]: D_loss: 1.158, G_loss: 1.243\n",
            "Epoch: [17/500]: D_loss: 1.156, G_loss: 1.197\n",
            "Epoch: [18/500]: D_loss: 1.193, G_loss: 1.161\n",
            "Epoch: [19/500]: D_loss: 1.201, G_loss: 1.129\n",
            "Epoch: [20/500]: D_loss: 1.201, G_loss: 1.108\n",
            "Epoch: [21/500]: D_loss: 1.214, G_loss: 1.092\n",
            "Epoch: [22/500]: D_loss: 1.202, G_loss: 1.116\n",
            "Epoch: [23/500]: D_loss: 1.223, G_loss: 1.078\n",
            "Epoch: [24/500]: D_loss: 1.225, G_loss: 1.056\n",
            "Epoch: [25/500]: D_loss: 1.213, G_loss: 1.089\n",
            "Epoch: [26/500]: D_loss: 1.231, G_loss: 1.049\n",
            "Epoch: [27/500]: D_loss: 1.222, G_loss: 1.048\n",
            "Epoch: [28/500]: D_loss: 1.230, G_loss: 1.056\n",
            "Epoch: [29/500]: D_loss: 1.207, G_loss: 1.080\n",
            "Epoch: [30/500]: D_loss: 1.181, G_loss: 1.127\n",
            "Epoch: [31/500]: D_loss: 1.224, G_loss: 1.050\n",
            "Epoch: [32/500]: D_loss: 1.228, G_loss: 1.027\n",
            "Epoch: [33/500]: D_loss: 1.238, G_loss: 1.027\n",
            "Epoch: [34/500]: D_loss: 1.244, G_loss: 1.001\n",
            "Epoch: [35/500]: D_loss: 1.243, G_loss: 1.014\n",
            "Epoch: [36/500]: D_loss: 1.248, G_loss: 1.002\n",
            "Epoch: [37/500]: D_loss: 1.237, G_loss: 1.033\n",
            "Epoch: [38/500]: D_loss: 1.245, G_loss: 1.014\n",
            "Epoch: [39/500]: D_loss: 1.238, G_loss: 1.015\n",
            "Epoch: [40/500]: D_loss: 1.240, G_loss: 1.014\n",
            "Epoch: [41/500]: D_loss: 1.237, G_loss: 1.014\n",
            "Epoch: [42/500]: D_loss: 1.233, G_loss: 1.013\n",
            "Epoch: [43/500]: D_loss: 1.238, G_loss: 1.015\n",
            "Epoch: [44/500]: D_loss: 1.240, G_loss: 0.995\n",
            "Epoch: [45/500]: D_loss: 1.238, G_loss: 1.011\n",
            "Epoch: [46/500]: D_loss: 1.242, G_loss: 1.002\n",
            "Epoch: [47/500]: D_loss: 1.235, G_loss: 1.006\n",
            "Epoch: [48/500]: D_loss: 1.241, G_loss: 1.000\n",
            "Epoch: [49/500]: D_loss: 1.221, G_loss: 1.022\n",
            "Epoch: [50/500]: D_loss: 1.235, G_loss: 1.002\n",
            "Epoch: [51/500]: D_loss: 1.233, G_loss: 1.011\n",
            "Epoch: [52/500]: D_loss: 1.221, G_loss: 1.023\n",
            "Epoch: [53/500]: D_loss: 1.241, G_loss: 1.004\n",
            "Epoch: [54/500]: D_loss: 1.239, G_loss: 1.002\n",
            "Epoch: [55/500]: D_loss: 1.233, G_loss: 1.015\n",
            "Epoch: [56/500]: D_loss: 1.224, G_loss: 1.021\n",
            "Epoch: [57/500]: D_loss: 1.231, G_loss: 1.007\n",
            "Epoch: [58/500]: D_loss: 1.224, G_loss: 1.011\n",
            "Epoch: [59/500]: D_loss: 1.232, G_loss: 1.003\n",
            "Epoch: [60/500]: D_loss: 1.230, G_loss: 0.999\n",
            "Epoch: [61/500]: D_loss: 1.228, G_loss: 1.020\n",
            "Epoch: [62/500]: D_loss: 1.226, G_loss: 1.021\n",
            "Epoch: [63/500]: D_loss: 1.218, G_loss: 1.027\n",
            "Epoch: [64/500]: D_loss: 1.225, G_loss: 1.014\n",
            "Epoch: [65/500]: D_loss: 1.222, G_loss: 1.019\n",
            "Epoch: [66/500]: D_loss: 1.216, G_loss: 1.031\n",
            "Epoch: [67/500]: D_loss: 1.230, G_loss: 1.010\n",
            "Epoch: [68/500]: D_loss: 1.222, G_loss: 1.005\n",
            "Epoch: [69/500]: D_loss: 1.224, G_loss: 1.017\n",
            "Epoch: [70/500]: D_loss: 1.210, G_loss: 1.038\n",
            "Epoch: [71/500]: D_loss: 1.218, G_loss: 1.029\n",
            "Epoch: [72/500]: D_loss: 1.205, G_loss: 1.045\n",
            "Epoch: [73/500]: D_loss: 1.217, G_loss: 1.032\n",
            "Epoch: [74/500]: D_loss: 1.210, G_loss: 1.039\n",
            "Epoch: [75/500]: D_loss: 1.210, G_loss: 1.035\n",
            "Epoch: [76/500]: D_loss: 1.204, G_loss: 1.049\n",
            "Epoch: [77/500]: D_loss: 1.208, G_loss: 1.038\n",
            "Epoch: [78/500]: D_loss: 1.219, G_loss: 1.026\n",
            "Epoch: [79/500]: D_loss: 1.196, G_loss: 1.045\n",
            "Epoch: [80/500]: D_loss: 1.203, G_loss: 1.050\n",
            "Epoch: [81/500]: D_loss: 1.199, G_loss: 1.054\n",
            "Epoch: [82/500]: D_loss: 1.201, G_loss: 1.059\n",
            "Epoch: [83/500]: D_loss: 1.197, G_loss: 1.059\n",
            "Epoch: [84/500]: D_loss: 1.199, G_loss: 1.057\n",
            "Epoch: [85/500]: D_loss: 1.197, G_loss: 1.050\n",
            "Epoch: [86/500]: D_loss: 1.194, G_loss: 1.060\n",
            "Epoch: [87/500]: D_loss: 1.201, G_loss: 1.045\n",
            "Epoch: [88/500]: D_loss: 1.197, G_loss: 1.056\n",
            "Epoch: [89/500]: D_loss: 1.201, G_loss: 1.058\n",
            "Epoch: [90/500]: D_loss: 1.190, G_loss: 1.056\n",
            "Epoch: [91/500]: D_loss: 1.192, G_loss: 1.062\n",
            "Epoch: [92/500]: D_loss: 1.188, G_loss: 1.059\n",
            "Epoch: [93/500]: D_loss: 1.180, G_loss: 1.078\n",
            "Epoch: [94/500]: D_loss: 1.183, G_loss: 1.076\n",
            "Epoch: [95/500]: D_loss: 1.190, G_loss: 1.072\n",
            "Epoch: [96/500]: D_loss: 1.179, G_loss: 1.070\n",
            "Epoch: [97/500]: D_loss: 1.184, G_loss: 1.072\n",
            "Epoch: [98/500]: D_loss: 1.174, G_loss: 1.089\n",
            "Epoch: [99/500]: D_loss: 1.180, G_loss: 1.079\n",
            "Epoch: [100/500]: D_loss: 1.177, G_loss: 1.078\n",
            "Epoch: [101/500]: D_loss: 1.185, G_loss: 1.075\n",
            "Epoch: [102/500]: D_loss: 1.182, G_loss: 1.071\n",
            "Epoch: [103/500]: D_loss: 1.172, G_loss: 1.085\n",
            "Epoch: [104/500]: D_loss: 1.166, G_loss: 1.095\n",
            "Epoch: [105/500]: D_loss: 1.170, G_loss: 1.097\n",
            "Epoch: [106/500]: D_loss: 1.173, G_loss: 1.091\n",
            "Epoch: [107/500]: D_loss: 1.178, G_loss: 1.092\n",
            "Epoch: [108/500]: D_loss: 1.169, G_loss: 1.104\n",
            "Epoch: [109/500]: D_loss: 1.168, G_loss: 1.097\n",
            "Epoch: [110/500]: D_loss: 1.160, G_loss: 1.108\n",
            "Epoch: [111/500]: D_loss: 1.170, G_loss: 1.104\n",
            "Epoch: [112/500]: D_loss: 1.171, G_loss: 1.092\n",
            "Epoch: [113/500]: D_loss: 1.166, G_loss: 1.103\n",
            "Epoch: [114/500]: D_loss: 1.167, G_loss: 1.101\n",
            "Epoch: [115/500]: D_loss: 1.166, G_loss: 1.107\n",
            "Epoch: [116/500]: D_loss: 1.171, G_loss: 1.101\n",
            "Epoch: [117/500]: D_loss: 1.161, G_loss: 1.109\n",
            "Epoch: [118/500]: D_loss: 1.162, G_loss: 1.108\n",
            "Epoch: [119/500]: D_loss: 1.165, G_loss: 1.110\n",
            "Epoch: [120/500]: D_loss: 1.164, G_loss: 1.103\n",
            "Epoch: [121/500]: D_loss: 1.156, G_loss: 1.119\n",
            "Epoch: [122/500]: D_loss: 1.154, G_loss: 1.116\n",
            "Epoch: [123/500]: D_loss: 1.165, G_loss: 1.105\n",
            "Epoch: [124/500]: D_loss: 1.158, G_loss: 1.111\n",
            "Epoch: [125/500]: D_loss: 1.159, G_loss: 1.111\n",
            "Epoch: [126/500]: D_loss: 1.157, G_loss: 1.115\n",
            "Epoch: [127/500]: D_loss: 1.159, G_loss: 1.119\n",
            "Epoch: [128/500]: D_loss: 1.158, G_loss: 1.106\n",
            "Epoch: [129/500]: D_loss: 1.154, G_loss: 1.122\n",
            "Epoch: [130/500]: D_loss: 1.153, G_loss: 1.114\n",
            "Epoch: [131/500]: D_loss: 1.148, G_loss: 1.124\n",
            "Epoch: [132/500]: D_loss: 1.159, G_loss: 1.119\n",
            "Epoch: [133/500]: D_loss: 1.159, G_loss: 1.115\n",
            "Epoch: [134/500]: D_loss: 1.154, G_loss: 1.125\n",
            "Epoch: [135/500]: D_loss: 1.146, G_loss: 1.128\n",
            "Epoch: [136/500]: D_loss: 1.154, G_loss: 1.118\n",
            "Epoch: [137/500]: D_loss: 1.144, G_loss: 1.130\n",
            "Epoch: [138/500]: D_loss: 1.143, G_loss: 1.138\n",
            "Epoch: [139/500]: D_loss: 1.149, G_loss: 1.135\n",
            "Epoch: [140/500]: D_loss: 1.144, G_loss: 1.129\n",
            "Epoch: [141/500]: D_loss: 1.141, G_loss: 1.131\n",
            "Epoch: [142/500]: D_loss: 1.146, G_loss: 1.126\n",
            "Epoch: [143/500]: D_loss: 1.145, G_loss: 1.129\n",
            "Epoch: [144/500]: D_loss: 1.144, G_loss: 1.140\n",
            "Epoch: [145/500]: D_loss: 1.140, G_loss: 1.149\n",
            "Epoch: [146/500]: D_loss: 1.140, G_loss: 1.135\n",
            "Epoch: [147/500]: D_loss: 1.140, G_loss: 1.138\n",
            "Epoch: [148/500]: D_loss: 1.142, G_loss: 1.140\n",
            "Epoch: [149/500]: D_loss: 1.138, G_loss: 1.140\n",
            "Epoch: [150/500]: D_loss: 1.132, G_loss: 1.152\n",
            "Epoch: [151/500]: D_loss: 1.136, G_loss: 1.142\n",
            "Epoch: [152/500]: D_loss: 1.131, G_loss: 1.157\n",
            "Epoch: [153/500]: D_loss: 1.135, G_loss: 1.157\n",
            "Epoch: [154/500]: D_loss: 1.136, G_loss: 1.148\n",
            "Epoch: [155/500]: D_loss: 1.139, G_loss: 1.145\n",
            "Epoch: [156/500]: D_loss: 1.131, G_loss: 1.153\n",
            "Epoch: [157/500]: D_loss: 1.134, G_loss: 1.143\n",
            "Epoch: [158/500]: D_loss: 1.132, G_loss: 1.155\n",
            "Epoch: [159/500]: D_loss: 1.130, G_loss: 1.158\n",
            "Epoch: [160/500]: D_loss: 1.133, G_loss: 1.149\n",
            "Epoch: [161/500]: D_loss: 1.119, G_loss: 1.166\n",
            "Epoch: [162/500]: D_loss: 1.128, G_loss: 1.157\n",
            "Epoch: [163/500]: D_loss: 1.131, G_loss: 1.155\n",
            "Epoch: [164/500]: D_loss: 1.129, G_loss: 1.164\n",
            "Epoch: [165/500]: D_loss: 1.132, G_loss: 1.160\n",
            "Epoch: [166/500]: D_loss: 1.126, G_loss: 1.165\n",
            "Epoch: [167/500]: D_loss: 1.123, G_loss: 1.172\n",
            "Epoch: [168/500]: D_loss: 1.129, G_loss: 1.162\n",
            "Epoch: [169/500]: D_loss: 1.126, G_loss: 1.159\n",
            "Epoch: [170/500]: D_loss: 1.124, G_loss: 1.167\n",
            "Epoch: [171/500]: D_loss: 1.124, G_loss: 1.176\n",
            "Epoch: [172/500]: D_loss: 1.122, G_loss: 1.174\n",
            "Epoch: [173/500]: D_loss: 1.118, G_loss: 1.178\n",
            "Epoch: [174/500]: D_loss: 1.119, G_loss: 1.174\n",
            "Epoch: [175/500]: D_loss: 1.120, G_loss: 1.173\n",
            "Epoch: [176/500]: D_loss: 1.108, G_loss: 1.188\n",
            "Epoch: [177/500]: D_loss: 1.115, G_loss: 1.188\n",
            "Epoch: [178/500]: D_loss: 1.113, G_loss: 1.186\n",
            "Epoch: [179/500]: D_loss: 1.115, G_loss: 1.179\n",
            "Epoch: [180/500]: D_loss: 1.123, G_loss: 1.176\n",
            "Epoch: [181/500]: D_loss: 1.122, G_loss: 1.170\n",
            "Epoch: [182/500]: D_loss: 1.113, G_loss: 1.187\n",
            "Epoch: [183/500]: D_loss: 1.118, G_loss: 1.181\n",
            "Epoch: [184/500]: D_loss: 1.117, G_loss: 1.188\n",
            "Epoch: [185/500]: D_loss: 1.116, G_loss: 1.181\n",
            "Epoch: [186/500]: D_loss: 1.119, G_loss: 1.169\n",
            "Epoch: [187/500]: D_loss: 1.113, G_loss: 1.198\n",
            "Epoch: [188/500]: D_loss: 1.117, G_loss: 1.184\n",
            "Epoch: [189/500]: D_loss: 1.112, G_loss: 1.190\n",
            "Epoch: [190/500]: D_loss: 1.110, G_loss: 1.188\n",
            "Epoch: [191/500]: D_loss: 1.108, G_loss: 1.200\n",
            "Epoch: [192/500]: D_loss: 1.103, G_loss: 1.211\n",
            "Epoch: [193/500]: D_loss: 1.108, G_loss: 1.206\n",
            "Epoch: [194/500]: D_loss: 1.115, G_loss: 1.183\n",
            "Epoch: [195/500]: D_loss: 1.112, G_loss: 1.189\n",
            "Epoch: [196/500]: D_loss: 1.115, G_loss: 1.188\n",
            "Epoch: [197/500]: D_loss: 1.112, G_loss: 1.191\n",
            "Epoch: [198/500]: D_loss: 1.108, G_loss: 1.190\n",
            "Epoch: [199/500]: D_loss: 1.111, G_loss: 1.191\n",
            "Epoch: [200/500]: D_loss: 1.104, G_loss: 1.196\n",
            "Epoch: [201/500]: D_loss: 1.106, G_loss: 1.207\n",
            "Epoch: [202/500]: D_loss: 1.100, G_loss: 1.210\n",
            "Epoch: [203/500]: D_loss: 1.103, G_loss: 1.215\n",
            "Epoch: [204/500]: D_loss: 1.110, G_loss: 1.204\n",
            "Epoch: [205/500]: D_loss: 1.100, G_loss: 1.211\n",
            "Epoch: [206/500]: D_loss: 1.109, G_loss: 1.207\n",
            "Epoch: [207/500]: D_loss: 1.103, G_loss: 1.217\n",
            "Epoch: [208/500]: D_loss: 1.104, G_loss: 1.205\n",
            "Epoch: [209/500]: D_loss: 1.103, G_loss: 1.205\n",
            "Epoch: [210/500]: D_loss: 1.102, G_loss: 1.204\n",
            "Epoch: [211/500]: D_loss: 1.102, G_loss: 1.211\n",
            "Epoch: [212/500]: D_loss: 1.105, G_loss: 1.206\n",
            "Epoch: [213/500]: D_loss: 1.103, G_loss: 1.205\n",
            "Epoch: [214/500]: D_loss: 1.101, G_loss: 1.217\n",
            "Epoch: [215/500]: D_loss: 1.104, G_loss: 1.213\n",
            "Epoch: [216/500]: D_loss: 1.101, G_loss: 1.216\n",
            "Epoch: [217/500]: D_loss: 1.105, G_loss: 1.204\n",
            "Epoch: [218/500]: D_loss: 1.103, G_loss: 1.216\n",
            "Epoch: [219/500]: D_loss: 1.100, G_loss: 1.215\n",
            "Epoch: [220/500]: D_loss: 1.101, G_loss: 1.213\n",
            "Epoch: [221/500]: D_loss: 1.099, G_loss: 1.223\n",
            "Epoch: [222/500]: D_loss: 1.102, G_loss: 1.217\n",
            "Epoch: [223/500]: D_loss: 1.103, G_loss: 1.208\n",
            "Epoch: [224/500]: D_loss: 1.095, G_loss: 1.218\n",
            "Epoch: [225/500]: D_loss: 1.091, G_loss: 1.230\n",
            "Epoch: [226/500]: D_loss: 1.103, G_loss: 1.221\n",
            "Epoch: [227/500]: D_loss: 1.101, G_loss: 1.213\n",
            "Epoch: [228/500]: D_loss: 1.104, G_loss: 1.221\n",
            "Epoch: [229/500]: D_loss: 1.090, G_loss: 1.235\n",
            "Epoch: [230/500]: D_loss: 1.099, G_loss: 1.226\n",
            "Epoch: [231/500]: D_loss: 1.095, G_loss: 1.227\n",
            "Epoch: [232/500]: D_loss: 1.100, G_loss: 1.225\n",
            "Epoch: [233/500]: D_loss: 1.097, G_loss: 1.224\n",
            "Epoch: [234/500]: D_loss: 1.098, G_loss: 1.213\n",
            "Epoch: [235/500]: D_loss: 1.099, G_loss: 1.220\n",
            "Epoch: [236/500]: D_loss: 1.091, G_loss: 1.230\n",
            "Epoch: [237/500]: D_loss: 1.086, G_loss: 1.238\n",
            "Epoch: [238/500]: D_loss: 1.102, G_loss: 1.217\n",
            "Epoch: [239/500]: D_loss: 1.099, G_loss: 1.218\n",
            "Epoch: [240/500]: D_loss: 1.092, G_loss: 1.227\n",
            "Epoch: [241/500]: D_loss: 1.091, G_loss: 1.228\n",
            "Epoch: [242/500]: D_loss: 1.099, G_loss: 1.223\n",
            "Epoch: [243/500]: D_loss: 1.086, G_loss: 1.230\n",
            "Epoch: [244/500]: D_loss: 1.090, G_loss: 1.236\n",
            "Epoch: [245/500]: D_loss: 1.090, G_loss: 1.234\n",
            "Epoch: [246/500]: D_loss: 1.091, G_loss: 1.228\n",
            "Epoch: [247/500]: D_loss: 1.085, G_loss: 1.243\n",
            "Epoch: [248/500]: D_loss: 1.096, G_loss: 1.231\n",
            "Epoch: [249/500]: D_loss: 1.098, G_loss: 1.218\n",
            "Epoch: [250/500]: D_loss: 1.088, G_loss: 1.235\n",
            "Epoch: [251/500]: D_loss: 1.091, G_loss: 1.239\n",
            "Epoch: [252/500]: D_loss: 1.092, G_loss: 1.232\n",
            "Epoch: [253/500]: D_loss: 1.085, G_loss: 1.243\n",
            "Epoch: [254/500]: D_loss: 1.087, G_loss: 1.241\n",
            "Epoch: [255/500]: D_loss: 1.092, G_loss: 1.240\n",
            "Epoch: [256/500]: D_loss: 1.090, G_loss: 1.236\n",
            "Epoch: [257/500]: D_loss: 1.091, G_loss: 1.238\n",
            "Epoch: [258/500]: D_loss: 1.093, G_loss: 1.232\n",
            "Epoch: [259/500]: D_loss: 1.093, G_loss: 1.239\n",
            "Epoch: [260/500]: D_loss: 1.083, G_loss: 1.259\n",
            "Epoch: [261/500]: D_loss: 1.091, G_loss: 1.240\n",
            "Epoch: [262/500]: D_loss: 1.087, G_loss: 1.239\n",
            "Epoch: [263/500]: D_loss: 1.087, G_loss: 1.247\n",
            "Epoch: [264/500]: D_loss: 1.091, G_loss: 1.241\n",
            "Epoch: [265/500]: D_loss: 1.087, G_loss: 1.239\n",
            "Epoch: [266/500]: D_loss: 1.096, G_loss: 1.233\n",
            "Epoch: [267/500]: D_loss: 1.091, G_loss: 1.237\n",
            "Epoch: [268/500]: D_loss: 1.088, G_loss: 1.247\n",
            "Epoch: [269/500]: D_loss: 1.091, G_loss: 1.238\n",
            "Epoch: [270/500]: D_loss: 1.085, G_loss: 1.239\n",
            "Epoch: [271/500]: D_loss: 1.095, G_loss: 1.233\n",
            "Epoch: [272/500]: D_loss: 1.085, G_loss: 1.243\n",
            "Epoch: [273/500]: D_loss: 1.083, G_loss: 1.250\n",
            "Epoch: [274/500]: D_loss: 1.085, G_loss: 1.252\n",
            "Epoch: [275/500]: D_loss: 1.088, G_loss: 1.244\n",
            "Epoch: [276/500]: D_loss: 1.080, G_loss: 1.244\n",
            "Epoch: [277/500]: D_loss: 1.088, G_loss: 1.244\n",
            "Epoch: [278/500]: D_loss: 1.078, G_loss: 1.269\n",
            "Epoch: [279/500]: D_loss: 1.085, G_loss: 1.256\n",
            "Epoch: [280/500]: D_loss: 1.089, G_loss: 1.244\n",
            "Epoch: [281/500]: D_loss: 1.089, G_loss: 1.259\n",
            "Epoch: [282/500]: D_loss: 1.084, G_loss: 1.253\n",
            "Epoch: [283/500]: D_loss: 1.085, G_loss: 1.262\n",
            "Epoch: [284/500]: D_loss: 1.076, G_loss: 1.262\n",
            "Epoch: [285/500]: D_loss: 1.076, G_loss: 1.278\n",
            "Epoch: [286/500]: D_loss: 1.078, G_loss: 1.266\n",
            "Epoch: [287/500]: D_loss: 1.076, G_loss: 1.268\n",
            "Epoch: [288/500]: D_loss: 1.078, G_loss: 1.264\n",
            "Epoch: [289/500]: D_loss: 1.075, G_loss: 1.267\n",
            "Epoch: [290/500]: D_loss: 1.079, G_loss: 1.265\n",
            "Epoch: [291/500]: D_loss: 1.072, G_loss: 1.272\n",
            "Epoch: [292/500]: D_loss: 1.076, G_loss: 1.282\n",
            "Epoch: [293/500]: D_loss: 1.073, G_loss: 1.272\n",
            "Epoch: [294/500]: D_loss: 1.084, G_loss: 1.264\n",
            "Epoch: [295/500]: D_loss: 1.078, G_loss: 1.259\n",
            "Epoch: [296/500]: D_loss: 1.083, G_loss: 1.255\n",
            "Epoch: [297/500]: D_loss: 1.083, G_loss: 1.260\n",
            "Epoch: [298/500]: D_loss: 1.084, G_loss: 1.262\n",
            "Epoch: [299/500]: D_loss: 1.078, G_loss: 1.265\n",
            "Epoch: [300/500]: D_loss: 1.081, G_loss: 1.263\n",
            "Epoch: [301/500]: D_loss: 1.084, G_loss: 1.262\n",
            "Epoch: [302/500]: D_loss: 1.084, G_loss: 1.263\n",
            "Epoch: [303/500]: D_loss: 1.085, G_loss: 1.255\n",
            "Epoch: [304/500]: D_loss: 1.079, G_loss: 1.268\n",
            "Epoch: [305/500]: D_loss: 1.078, G_loss: 1.269\n",
            "Epoch: [306/500]: D_loss: 1.076, G_loss: 1.269\n",
            "Epoch: [307/500]: D_loss: 1.072, G_loss: 1.281\n",
            "Epoch: [308/500]: D_loss: 1.075, G_loss: 1.271\n",
            "Epoch: [309/500]: D_loss: 1.079, G_loss: 1.271\n",
            "Epoch: [310/500]: D_loss: 1.083, G_loss: 1.265\n",
            "Epoch: [311/500]: D_loss: 1.080, G_loss: 1.256\n",
            "Epoch: [312/500]: D_loss: 1.074, G_loss: 1.273\n",
            "Epoch: [313/500]: D_loss: 1.076, G_loss: 1.265\n",
            "Epoch: [314/500]: D_loss: 1.078, G_loss: 1.277\n",
            "Epoch: [315/500]: D_loss: 1.079, G_loss: 1.266\n",
            "Epoch: [316/500]: D_loss: 1.079, G_loss: 1.264\n",
            "Epoch: [317/500]: D_loss: 1.079, G_loss: 1.261\n",
            "Epoch: [318/500]: D_loss: 1.080, G_loss: 1.264\n",
            "Epoch: [319/500]: D_loss: 1.077, G_loss: 1.268\n",
            "Epoch: [320/500]: D_loss: 1.087, G_loss: 1.259\n",
            "Epoch: [321/500]: D_loss: 1.079, G_loss: 1.267\n",
            "Epoch: [322/500]: D_loss: 1.074, G_loss: 1.277\n",
            "Epoch: [323/500]: D_loss: 1.076, G_loss: 1.282\n",
            "Epoch: [324/500]: D_loss: 1.069, G_loss: 1.276\n",
            "Epoch: [325/500]: D_loss: 1.067, G_loss: 1.285\n",
            "Epoch: [326/500]: D_loss: 1.073, G_loss: 1.283\n",
            "Epoch: [327/500]: D_loss: 1.073, G_loss: 1.276\n",
            "Epoch: [328/500]: D_loss: 1.080, G_loss: 1.268\n",
            "Epoch: [329/500]: D_loss: 1.077, G_loss: 1.275\n",
            "Epoch: [330/500]: D_loss: 1.075, G_loss: 1.270\n",
            "Epoch: [331/500]: D_loss: 1.071, G_loss: 1.283\n",
            "Epoch: [332/500]: D_loss: 1.076, G_loss: 1.273\n",
            "Epoch: [333/500]: D_loss: 1.071, G_loss: 1.279\n",
            "Epoch: [334/500]: D_loss: 1.067, G_loss: 1.287\n",
            "Epoch: [335/500]: D_loss: 1.070, G_loss: 1.283\n",
            "Epoch: [336/500]: D_loss: 1.070, G_loss: 1.279\n",
            "Epoch: [337/500]: D_loss: 1.064, G_loss: 1.289\n",
            "Epoch: [338/500]: D_loss: 1.068, G_loss: 1.284\n",
            "Epoch: [339/500]: D_loss: 1.065, G_loss: 1.294\n",
            "Epoch: [340/500]: D_loss: 1.071, G_loss: 1.290\n",
            "Epoch: [341/500]: D_loss: 1.059, G_loss: 1.291\n",
            "Epoch: [342/500]: D_loss: 1.067, G_loss: 1.286\n",
            "Epoch: [343/500]: D_loss: 1.073, G_loss: 1.281\n",
            "Epoch: [344/500]: D_loss: 1.071, G_loss: 1.286\n",
            "Epoch: [345/500]: D_loss: 1.060, G_loss: 1.298\n",
            "Epoch: [346/500]: D_loss: 1.062, G_loss: 1.291\n",
            "Epoch: [347/500]: D_loss: 1.066, G_loss: 1.299\n",
            "Epoch: [348/500]: D_loss: 1.065, G_loss: 1.293\n",
            "Epoch: [349/500]: D_loss: 1.061, G_loss: 1.296\n",
            "Epoch: [350/500]: D_loss: 1.063, G_loss: 1.302\n",
            "Epoch: [351/500]: D_loss: 1.067, G_loss: 1.292\n",
            "Epoch: [352/500]: D_loss: 1.060, G_loss: 1.299\n",
            "Epoch: [353/500]: D_loss: 1.069, G_loss: 1.291\n",
            "Epoch: [354/500]: D_loss: 1.066, G_loss: 1.297\n",
            "Epoch: [355/500]: D_loss: 1.066, G_loss: 1.293\n",
            "Epoch: [356/500]: D_loss: 1.062, G_loss: 1.288\n",
            "Epoch: [357/500]: D_loss: 1.062, G_loss: 1.304\n",
            "Epoch: [358/500]: D_loss: 1.058, G_loss: 1.306\n",
            "Epoch: [359/500]: D_loss: 1.067, G_loss: 1.293\n",
            "Epoch: [360/500]: D_loss: 1.064, G_loss: 1.289\n",
            "Epoch: [361/500]: D_loss: 1.063, G_loss: 1.300\n",
            "Epoch: [362/500]: D_loss: 1.064, G_loss: 1.295\n",
            "Epoch: [363/500]: D_loss: 1.067, G_loss: 1.294\n",
            "Epoch: [364/500]: D_loss: 1.063, G_loss: 1.302\n",
            "Epoch: [365/500]: D_loss: 1.070, G_loss: 1.290\n",
            "Epoch: [366/500]: D_loss: 1.070, G_loss: 1.290\n",
            "Epoch: [367/500]: D_loss: 1.069, G_loss: 1.293\n",
            "Epoch: [368/500]: D_loss: 1.059, G_loss: 1.310\n",
            "Epoch: [369/500]: D_loss: 1.066, G_loss: 1.302\n",
            "Epoch: [370/500]: D_loss: 1.069, G_loss: 1.300\n",
            "Epoch: [371/500]: D_loss: 1.071, G_loss: 1.292\n",
            "Epoch: [372/500]: D_loss: 1.066, G_loss: 1.296\n",
            "Epoch: [373/500]: D_loss: 1.060, G_loss: 1.300\n",
            "Epoch: [374/500]: D_loss: 1.056, G_loss: 1.308\n",
            "Epoch: [375/500]: D_loss: 1.061, G_loss: 1.303\n",
            "Epoch: [376/500]: D_loss: 1.058, G_loss: 1.309\n",
            "Epoch: [377/500]: D_loss: 1.061, G_loss: 1.311\n",
            "Epoch: [378/500]: D_loss: 1.052, G_loss: 1.314\n",
            "Epoch: [379/500]: D_loss: 1.057, G_loss: 1.310\n",
            "Epoch: [380/500]: D_loss: 1.062, G_loss: 1.314\n",
            "Epoch: [381/500]: D_loss: 1.064, G_loss: 1.307\n",
            "Epoch: [382/500]: D_loss: 1.064, G_loss: 1.302\n",
            "Epoch: [383/500]: D_loss: 1.059, G_loss: 1.308\n",
            "Epoch: [384/500]: D_loss: 1.061, G_loss: 1.310\n",
            "Epoch: [385/500]: D_loss: 1.054, G_loss: 1.317\n",
            "Epoch: [386/500]: D_loss: 1.056, G_loss: 1.315\n",
            "Epoch: [387/500]: D_loss: 1.052, G_loss: 1.322\n",
            "Epoch: [388/500]: D_loss: 1.052, G_loss: 1.321\n",
            "Epoch: [389/500]: D_loss: 1.055, G_loss: 1.310\n",
            "Epoch: [390/500]: D_loss: 1.052, G_loss: 1.322\n",
            "Epoch: [391/500]: D_loss: 1.050, G_loss: 1.329\n",
            "Epoch: [392/500]: D_loss: 1.053, G_loss: 1.316\n",
            "Epoch: [393/500]: D_loss: 1.053, G_loss: 1.321\n",
            "Epoch: [394/500]: D_loss: 1.053, G_loss: 1.314\n",
            "Epoch: [395/500]: D_loss: 1.058, G_loss: 1.315\n",
            "Epoch: [396/500]: D_loss: 1.059, G_loss: 1.311\n",
            "Epoch: [397/500]: D_loss: 1.051, G_loss: 1.326\n",
            "Epoch: [398/500]: D_loss: 1.051, G_loss: 1.325\n",
            "Epoch: [399/500]: D_loss: 1.046, G_loss: 1.332\n",
            "Epoch: [400/500]: D_loss: 1.046, G_loss: 1.331\n",
            "Epoch: [401/500]: D_loss: 1.050, G_loss: 1.327\n",
            "Epoch: [402/500]: D_loss: 1.050, G_loss: 1.328\n",
            "Epoch: [403/500]: D_loss: 1.055, G_loss: 1.321\n",
            "Epoch: [404/500]: D_loss: 1.059, G_loss: 1.321\n",
            "Epoch: [405/500]: D_loss: 1.058, G_loss: 1.314\n",
            "Epoch: [406/500]: D_loss: 1.046, G_loss: 1.329\n",
            "Epoch: [407/500]: D_loss: 1.051, G_loss: 1.331\n",
            "Epoch: [408/500]: D_loss: 1.055, G_loss: 1.321\n",
            "Epoch: [409/500]: D_loss: 1.054, G_loss: 1.324\n",
            "Epoch: [410/500]: D_loss: 1.048, G_loss: 1.333\n",
            "Epoch: [411/500]: D_loss: 1.049, G_loss: 1.332\n",
            "Epoch: [412/500]: D_loss: 1.051, G_loss: 1.332\n",
            "Epoch: [413/500]: D_loss: 1.043, G_loss: 1.336\n",
            "Epoch: [414/500]: D_loss: 1.047, G_loss: 1.337\n",
            "Epoch: [416/500]: D_loss: 1.052, G_loss: 1.331\n",
            "Epoch: [417/500]: D_loss: 1.051, G_loss: 1.337\n",
            "Epoch: [418/500]: D_loss: 1.052, G_loss: 1.337\n",
            "Epoch: [419/500]: D_loss: 1.047, G_loss: 1.328\n",
            "Epoch: [420/500]: D_loss: 1.049, G_loss: 1.325\n",
            "Epoch: [421/500]: D_loss: 1.053, G_loss: 1.328\n",
            "Epoch: [422/500]: D_loss: 1.048, G_loss: 1.330\n",
            "Epoch: [423/500]: D_loss: 1.045, G_loss: 1.333\n",
            "Epoch: [424/500]: D_loss: 1.052, G_loss: 1.331\n",
            "Epoch: [425/500]: D_loss: 1.049, G_loss: 1.326\n",
            "Epoch: [426/500]: D_loss: 1.054, G_loss: 1.321\n",
            "Epoch: [427/500]: D_loss: 1.055, G_loss: 1.327\n",
            "Epoch: [428/500]: D_loss: 1.052, G_loss: 1.329\n",
            "Epoch: [429/500]: D_loss: 1.053, G_loss: 1.329\n",
            "Epoch: [430/500]: D_loss: 1.044, G_loss: 1.331\n",
            "Epoch: [431/500]: D_loss: 1.044, G_loss: 1.337\n",
            "Epoch: [432/500]: D_loss: 1.044, G_loss: 1.335\n",
            "Epoch: [433/500]: D_loss: 1.045, G_loss: 1.337\n",
            "Epoch: [434/500]: D_loss: 1.046, G_loss: 1.333\n",
            "Epoch: [435/500]: D_loss: 1.047, G_loss: 1.343\n",
            "Epoch: [436/500]: D_loss: 1.052, G_loss: 1.330\n",
            "Epoch: [437/500]: D_loss: 1.055, G_loss: 1.335\n",
            "Epoch: [438/500]: D_loss: 1.054, G_loss: 1.337\n",
            "Epoch: [439/500]: D_loss: 1.032, G_loss: 1.356\n",
            "Epoch: [440/500]: D_loss: 1.034, G_loss: 1.354\n",
            "Epoch: [441/500]: D_loss: 1.029, G_loss: 1.357\n",
            "Epoch: [442/500]: D_loss: 1.038, G_loss: 1.348\n",
            "Epoch: [443/500]: D_loss: 1.037, G_loss: 1.351\n",
            "Epoch: [444/500]: D_loss: 1.038, G_loss: 1.355\n",
            "Epoch: [445/500]: D_loss: 1.045, G_loss: 1.348\n",
            "Epoch: [446/500]: D_loss: 1.044, G_loss: 1.342\n",
            "Epoch: [447/500]: D_loss: 1.052, G_loss: 1.331\n",
            "Epoch: [448/500]: D_loss: 1.038, G_loss: 1.348\n",
            "Epoch: [449/500]: D_loss: 1.045, G_loss: 1.353\n",
            "Epoch: [450/500]: D_loss: 1.043, G_loss: 1.344\n",
            "Epoch: [451/500]: D_loss: 1.042, G_loss: 1.351\n",
            "Epoch: [452/500]: D_loss: 1.047, G_loss: 1.338\n",
            "Epoch: [453/500]: D_loss: 1.041, G_loss: 1.348\n",
            "Epoch: [454/500]: D_loss: 1.044, G_loss: 1.348\n",
            "Epoch: [455/500]: D_loss: 1.041, G_loss: 1.356\n",
            "Epoch: [456/500]: D_loss: 1.045, G_loss: 1.346\n",
            "Epoch: [457/500]: D_loss: 1.050, G_loss: 1.339\n",
            "Epoch: [458/500]: D_loss: 1.043, G_loss: 1.352\n",
            "Epoch: [459/500]: D_loss: 1.039, G_loss: 1.355\n",
            "Epoch: [460/500]: D_loss: 1.034, G_loss: 1.360\n",
            "Epoch: [461/500]: D_loss: 1.040, G_loss: 1.351\n",
            "Epoch: [462/500]: D_loss: 1.040, G_loss: 1.343\n",
            "Epoch: [463/500]: D_loss: 1.045, G_loss: 1.346\n",
            "Epoch: [464/500]: D_loss: 1.045, G_loss: 1.344\n",
            "Epoch: [465/500]: D_loss: 1.039, G_loss: 1.348\n",
            "Epoch: [466/500]: D_loss: 1.047, G_loss: 1.345\n",
            "Epoch: [467/500]: D_loss: 1.038, G_loss: 1.355\n",
            "Epoch: [468/500]: D_loss: 1.036, G_loss: 1.352\n",
            "Epoch: [469/500]: D_loss: 1.036, G_loss: 1.357\n",
            "Epoch: [470/500]: D_loss: 1.035, G_loss: 1.364\n",
            "Epoch: [471/500]: D_loss: 1.037, G_loss: 1.358\n",
            "Epoch: [472/500]: D_loss: 1.042, G_loss: 1.353\n",
            "Epoch: [473/500]: D_loss: 1.043, G_loss: 1.359\n",
            "Epoch: [474/500]: D_loss: 1.045, G_loss: 1.356\n",
            "Epoch: [475/500]: D_loss: 1.046, G_loss: 1.351\n",
            "Epoch: [476/500]: D_loss: 1.041, G_loss: 1.357\n",
            "Epoch: [477/500]: D_loss: 1.042, G_loss: 1.354\n",
            "Epoch: [478/500]: D_loss: 1.030, G_loss: 1.370\n",
            "Epoch: [479/500]: D_loss: 1.032, G_loss: 1.364\n",
            "Epoch: [480/500]: D_loss: 1.033, G_loss: 1.367\n",
            "Epoch: [481/500]: D_loss: 1.030, G_loss: 1.366\n",
            "Epoch: [482/500]: D_loss: 1.031, G_loss: 1.368\n",
            "Epoch: [483/500]: D_loss: 1.036, G_loss: 1.372\n",
            "Epoch: [484/500]: D_loss: 1.026, G_loss: 1.377\n",
            "Epoch: [485/500]: D_loss: 1.025, G_loss: 1.376\n",
            "Epoch: [486/500]: D_loss: 1.032, G_loss: 1.373\n",
            "Epoch: [487/500]: D_loss: 1.034, G_loss: 1.373\n",
            "Epoch: [488/500]: D_loss: 1.043, G_loss: 1.360\n",
            "Epoch: [489/500]: D_loss: 1.032, G_loss: 1.365\n",
            "Epoch: [490/500]: D_loss: 1.033, G_loss: 1.372\n",
            "Epoch: [491/500]: D_loss: 1.027, G_loss: 1.371\n",
            "Epoch: [492/500]: D_loss: 1.028, G_loss: 1.381\n",
            "Epoch: [493/500]: D_loss: 1.035, G_loss: 1.366\n",
            "Epoch: [494/500]: D_loss: 1.028, G_loss: 1.375\n",
            "Epoch: [495/500]: D_loss: 1.024, G_loss: 1.375\n",
            "Epoch: [496/500]: D_loss: 1.029, G_loss: 1.369\n",
            "Epoch: [497/500]: D_loss: 1.044, G_loss: 1.362\n",
            "Epoch: [498/500]: D_loss: 1.033, G_loss: 1.365\n",
            "Epoch: [499/500]: D_loss: 1.036, G_loss: 1.371\n",
            "Epoch: [500/500]: D_loss: 1.029, G_loss: 1.374\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 500\n",
        "D_loss_plot, G_loss_plot = [], []\n",
        "for epoch in range(1, num_epochs+1):\n",
        "\n",
        "    D_loss_list, G_loss_list = [], []\n",
        "\n",
        "    for index, (real_images, _) in enumerate(train_loader):\n",
        "        D_optimizer.zero_grad()\n",
        "        real_images = real_images.to(device)\n",
        "        real_target = Variable(torch.ones(real_images.size(0), 1).to(device))\n",
        "        fake_target = Variable(torch.zeros(real_images.size(0), 1).to(device))\n",
        "\n",
        "        D_real_loss = adversarial_loss(discriminator(real_images), real_target)\n",
        "        # print(discriminator(real_images))\n",
        "\n",
        "        noise_vector = Variable(torch.randn(real_images.size(0), latent_dim).to(device))\n",
        "        #noise_vector = Variable(Tensor(np.random.normal(0, 1, \\\n",
        "        #                                                (real_images.size(0),\\\n",
        "        #                                                 latent_dim))))\n",
        "        noise_vector = noise_vector.to(device)\n",
        "        generated_image = generator(noise_vector)\n",
        "\n",
        "        D_fake_loss = adversarial_loss(discriminator(generated_image),\\\n",
        "                                     fake_target)\n",
        "\n",
        "        D_total_loss = D_real_loss + D_fake_loss\n",
        "        D_loss_list.append(D_total_loss)\n",
        "        D_total_loss.backward()\n",
        "        D_optimizer.step()\n",
        "\n",
        "        G_optimizer.zero_grad()\n",
        "        generated_image = generator(noise_vector)\n",
        "        G_loss = adversarial_loss(discriminator(generated_image), real_target)\n",
        "        G_loss_list.append(G_loss)\n",
        "\n",
        "        G_loss.backward()\n",
        "        G_optimizer.step()\n",
        "        d = generated_image.data\n",
        "\n",
        "        writer.add_scalar('Discriminator Loss',\n",
        "                            D_total_loss,\n",
        "                            epoch * len(train_loader) + index)\n",
        "\n",
        "        writer.add_scalar('Generator Loss',\n",
        "                            G_loss,\n",
        "                            epoch * len(train_loader) + index)\n",
        "\n",
        "\n",
        "    print('Epoch: [%d/%d]: D_loss: %.3f, G_loss: %.3f' % (\n",
        "            (epoch), num_epochs, torch.mean(torch.FloatTensor(D_loss_list)),\\\n",
        "             torch.mean(torch.FloatTensor(G_loss_list))))\n",
        "\n",
        "    D_loss_plot.append(torch.mean(torch.FloatTensor(D_loss_list)))\n",
        "    G_loss_plot.append(torch.mean(torch.FloatTensor(G_loss_list)))\n",
        "    save_image(generated_image.data[:90], 'diff-run/images/sample_%d'%epoch + '.png', nrow=10, normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VTrcM8It2K2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Tuts",
      "language": "python",
      "name": "tuts"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}