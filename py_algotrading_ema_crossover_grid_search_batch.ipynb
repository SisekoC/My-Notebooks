{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SisekoC/My-Notebooks/blob/main/py_algotrading_ema_crossover_grid_search_batch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAMfpjBWGWHT"
      },
      "source": [
        "# Algorithmic Trading Model for Exponential Moving Average Crossover Grid Search Batch Mode Using Colab\n",
        "### David Lowe\n",
        "### June 25, 2020\n",
        "\n",
        "NOTE: This script is for learning purposes only and does not constitute a recommendation for buying or selling any stock mentioned in this script.\n",
        "\n",
        "SUMMARY: The purpose of this project is to construct and test an algorithmic trading model and document the end-to-end steps using a template.\n",
        "\n",
        "INTRODUCTION: This algorithmic trading model examines a series of exponential moving average (MA) models via a grid search methodology. When the fast moving-average curve crosses above the slow moving-average curve, the strategy goes long (buys) on the stock. When the opposite occurs, we will exit the position.\n",
        "\n",
        "The grid search methodology will search through all combinations between the two MA curves. The faster MA curve can range from 5 days to 20 days, while the slower MA can range from 10 days to 50 days. Both curves use a 5-day increment.\n",
        "\n",
        "ANALYSIS: This is the Google Colab version of the iPython notebook posted on June 17, 2020. The script will save all output for each stock into a text file and on a Google Drive path. The Colab script contains an example of processing 100 different stocks in one batch.\n",
        "\n",
        "CONCLUSION: Please refer to the individual output file for each stock.\n",
        "\n",
        "Dataset ML Model: Time series analysis with numerical attributes\n",
        "\n",
        "Dataset Used: Quandl\n",
        "\n",
        "An algorithmic trading modeling project generally can be broken down into about five major tasks:\n",
        "\n",
        "1. Prepare Environment\n",
        "2. Acquire and Pre-Process Data\n",
        "3. Develop Strategy and Train Model\n",
        "4. Back-test Model\n",
        "5. Evaluate Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Deypdy4dHJhs"
      },
      "source": [
        "## Task 1. Prepare Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Q-ffFlU0MPM",
        "outputId": "ece70840-7a9f-4885-fb96-7d1f0a0a8ca8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting PyMySQL\n",
            "  Downloading PyMySQL-1.1.1-py3-none-any.whl.metadata (4.4 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading PyMySQL-1.1.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-dotenv, PyMySQL\n",
            "Successfully installed PyMySQL-1.1.1 python-dotenv-1.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install python-dotenv PyMySQ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vtFLAVHJgXN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import smtplib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime, timedelta\n",
        "from dotenv import load_dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlVtsVc7zWhK",
        "outputId": "0ac3f5a7-247a-4437-ab8a-bbe0f4f94116"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting date for the model: 2015-01-01 00:00:00\n",
            "Ending date for the model: 2020-08-03 00:00:00\n"
          ]
        }
      ],
      "source": [
        "# Specify the moving average parameters for the trading strategy\n",
        "initial_capital = 100000\n",
        "fast_ma_min = 5\n",
        "fast_ma_max = 20\n",
        "slow_ma_min = 10\n",
        "slow_ma_max = 50\n",
        "ma_increment = 5\n",
        "min_ma_gap = 5\n",
        "\n",
        "# The number of extra days of data we need (usually equals to the larger of slow_ema or slow_sma)\n",
        "extra_days_data = slow_ma_max\n",
        "\n",
        "model_start_date = datetime(2015, 1, 1)\n",
        "print(\"Starting date for the model:\", model_start_date)\n",
        "stock_start_date = model_start_date - timedelta(days=int(extra_days_data*1.5)) # Need more pricing data to calculate moving averages\n",
        "\n",
        "model_end_date = datetime.now()\n",
        "model_end_date = datetime(2020, 8, 3)\n",
        "print(\"Ending date for the model:\", model_end_date)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3Y5l3OPzWhL",
        "outputId": "1039c1d6-3dc4-4cde-aafa-32d08a2f446e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-446de732cf01>:31: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
            "  plt.style.use('seaborn')\n"
          ]
        }
      ],
      "source": [
        "# Begin the timer for the script processing\n",
        "startTimeScript = datetime.now()\n",
        "\n",
        "# Set up the verbose flag to print detailed messages for debugging (setting True will activate!)\n",
        "verbose_models = True\n",
        "verbose_graphs = True\n",
        "verbose_portfolios = True\n",
        "\n",
        "# Set up the sendNotification flag to send progress emails (setting True will send emails!)\n",
        "notifyStatus = True\n",
        "\n",
        "# Set up the parent directory location for loading the dotenv files\n",
        "useColab = True\n",
        "if useColab:\n",
        "    # Mount Google Drive locally for storing files\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "    gdrivePrefix = '/content/gdrive/My Drive/Colab_Downloads/'\n",
        "    env_path = '/content/gdrive/My Drive/Colab Notebooks/'\n",
        "    dotenv_path = env_path + \"python_script.env\"\n",
        "    load_dotenv(dotenv_path=dotenv_path)\n",
        "\n",
        "# Set up the dotenv file for retrieving environment variables\n",
        "useLocalPC = True\n",
        "if useLocalPC:\n",
        "    env_path = \"C:/Users/cubas/OneDrive/Documents/Github Projects/4 Quantitative Finance Projects/py_algotrading_ema_crossover_grid_search_batch_colab\"\n",
        "    dotenv_path = env_path + \"python_script.env\"\n",
        "    load_dotenv(dotenv_path=dotenv_path)\n",
        "\n",
        "# Configure the plotting style\n",
        "plt.style.use('seaborn')\n",
        "\n",
        "# Set Pandas options\n",
        "pd.set_option(\"display.max_rows\", 120)\n",
        "pd.set_option(\"display.max_columns\", 120)\n",
        "pd.set_option(\"display.width\", 140)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGcMIgUQJWpC"
      },
      "source": [
        "## Task 2. Acquire and Pre-Process Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9V3GM9OzWhL",
        "outputId": "4deb3547-adc5-45f6-c00d-00a8c9bdf41d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting quandl\n",
            "  Downloading Quandl-3.7.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: pandas>=0.14 in /usr/local/lib/python3.10/dist-packages (from quandl) (2.1.4)\n",
            "Requirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.10/dist-packages (from quandl) (1.26.4)\n",
            "Requirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from quandl) (2.32.3)\n",
            "Collecting inflection>=0.3.1 (from quandl)\n",
            "  Downloading inflection-0.5.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from quandl) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from quandl) (1.16.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from quandl) (10.3.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.14->quandl) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.14->quandl) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->quandl) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->quandl) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->quandl) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->quandl) (2024.7.4)\n",
            "Downloading Quandl-3.7.0-py2.py3-none-any.whl (26 kB)\n",
            "Downloading inflection-0.5.1-py2.py3-none-any.whl (9.5 kB)\n",
            "Installing collected packages: inflection, quandl\n",
            "Successfully installed inflection-0.5.1 quandl-3.7.0\n"
          ]
        }
      ],
      "source": [
        "pip install quandl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSoyiJiwzWhM"
      },
      "outputs": [],
      "source": [
        "# Check and see whether the API key is available\n",
        "import quandl\n",
        "quandl.ApiConfig.api_key = 'AywUrfKTvTTsCiRfWoWp'\n",
        "quandl_key = quandl.ApiConfig.api_key\n",
        "if quandl_key is None: sys.exit(\"API key for Quandl not available. Script Processing Aborted!!!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPwSy42szWhM"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "def task2_acquire_process_data(stock_symbol, stock_start_date, model_end_date, quandl_key):\n",
        "    start_date_string = stock_start_date.strftime('%Y-%m-%d')\n",
        "    end_date_string = model_end_date.strftime('%Y-%m-%d')\n",
        "    quandl_url = f\"https://www.quandl.com/api/v3/datatables/SHARADAR/SEP.json?date.gte={start_date_string}&date.lte={end_date_string}&ticker={stock_symbol}&api_key={quandl_key}\"\n",
        "\n",
        "    print(f'Fetching equity data from {start_date_string} to {end_date_string}')\n",
        "\n",
        "    try:\n",
        "        response = requests.get(quandl_url)\n",
        "        response.raise_for_status()  # Raise an error for bad status codes\n",
        "        quandl_dict = response.json()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching data: {e}\")\n",
        "        return None\n",
        "\n",
        "    stock_quandl = pd.DataFrame(quandl_dict['datatable']['data'])\n",
        "    print(f\"{len(stock_quandl)} data points retrieved from the API call.\")\n",
        "\n",
        "    stock_quandl.columns = ['ticker', 'date', 'open', 'high', 'low', 'close', 'volume', 'dividend', 'closeunadj', 'lastupdated']\n",
        "    stock_quandl['date'] = pd.to_datetime(stock_quandl['date'])  # Convert 'date' column to datetime\n",
        "    stock_quandl.set_index('date', inplace=True)\n",
        "    stock_quandl = stock_quandl.sort_index(ascending=True)\n",
        "\n",
        "    return stock_quandl\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gouG8Y7YIcNz"
      },
      "source": [
        "## Task 3. Develop Strategy and Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vTDOXtoIUuO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def task3_develop_strategy(stock_quandl, verbose=False):\n",
        "    # Select the data source and pricing columns to use for modeling\n",
        "    model_template = stock_quandl.loc[:, ['open', 'close']]\n",
        "\n",
        "    # Set up the standard column name for modeling\n",
        "    model_template.rename(columns={'open': 'open_price', 'close': 'close_price'}, inplace=True)\n",
        "    if verbose:\n",
        "        model_template.info(verbose=True)\n",
        "\n",
        "    # Initialize columns\n",
        "    model_template['ma_change'] = 0  # Assuming you have a way to calculate this\n",
        "    model_template['trade_signal'] = 0\n",
        "    model_template['signal_change'] = 0\n",
        "    model_template['entry_exit'] = 0\n",
        "\n",
        "    def trading_ma_crossover(model):\n",
        "        waitfor_first_entry = True\n",
        "        for x in range(len(model)):\n",
        "            if model['ma_change'].iloc[x] > 0:\n",
        "                model.loc[x, 'trade_signal'] = 1  # trade_signal = 1 means we should take a long position\n",
        "            else:\n",
        "                model.loc[x, 'trade_signal'] = 0  # trade_signal = 0 means we should take a flat position\n",
        "            if x != 0:\n",
        "                model.loc[x, 'signal_change'] = model['trade_signal'].iloc[x] - model['trade_signal'].iloc[x-1]\n",
        "                if waitfor_first_entry and (model['signal_change'].iloc[x-1] == 1):\n",
        "                    model.loc[x, 'entry_exit'] = model['signal_change'].iloc[x-1]\n",
        "                    waitfor_first_entry = False\n",
        "                elif (not waitfor_first_entry) and (model['signal_change'].iloc[x-1] != 0):\n",
        "                    model.loc[x, 'entry_exit'] = model['signal_change'].iloc[x-1]\n",
        "\n",
        "    trading_ma_crossover(model_template)\n",
        "    return model_template\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def generate_trading_models(model_template, slow_ma_min, slow_ma_max, fast_ma_min, fast_ma_max, ma_increment, min_ma_gap, model_start_date, model_end_date, verbose=False):\n",
        "    model_collection = {}\n",
        "    serial_number = 1\n",
        "    for slow_ma in range(slow_ma_min, slow_ma_max + 1, ma_increment):\n",
        "        for fast_ma in range(fast_ma_min, fast_ma_max + 1, ma_increment):\n",
        "            if (slow_ma - fast_ma) < min_ma_gap:\n",
        "                break\n",
        "            model_name = f'SMA_{str(serial_number).zfill(3)}_SlowMA_{str(slow_ma).zfill(2)}_FastMA_{str(fast_ma).zfill(2)}'\n",
        "            serial_number += 1\n",
        "            trading_model = model_template.copy()\n",
        "            trading_model['fast_ma'] = trading_model['close_price'].ewm(span=fast_ma).mean()\n",
        "            trading_model['slow_ma'] = trading_model['close_price'].ewm(span=slow_ma).mean()\n",
        "            trading_model['ma_change'] = trading_model['fast_ma'] - trading_model['slow_ma']\n",
        "            trading_model['trade_signal'] = np.zeros(len(trading_model))\n",
        "            trading_model['signal_change'] = np.zeros(len(trading_model))\n",
        "            trading_model['entry_exit'] = np.zeros(len(trading_model))\n",
        "            trading_model = trading_model[model_start_date:model_end_date]\n",
        "            trading_ma_crossover(trading_model, 'ma_change')\n",
        "            model_collection[model_name] = trading_model.copy()\n",
        "\n",
        "    print(f\"{serial_number - 1} models added to the trading model collection.\")\n",
        "    print()\n",
        "\n",
        "    # List the entry/exit points for each model\n",
        "    for key in model_collection:\n",
        "        if verbose:\n",
        "            print(f'List the signal change and entry/exit points for {key}')\n",
        "            print(model_collection[key][(model_collection[key].signal_change != 0) | (model_collection[key].entry_exit != 0)])\n",
        "            print()\n",
        "\n",
        "    return model_collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bYeJXxiIGQk"
      },
      "source": [
        "## Task 4. Back-test Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3S3PLa2H75W"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def task4_back_test_model(model_collection, initial_capital, verbose=False):\n",
        "    def trading_portfolio_generation(initial_capital, trading_model):\n",
        "        # Construct a portfolio to track the transactions and returns\n",
        "        portfolio = pd.DataFrame(index=trading_model.index, columns=['trade_action', 'qty_onhand', 'cost_basis', 'sold_transaction', 'gain_loss', 'cash_onhand', 'position_value', 'total_position', 'accumu_return'])\n",
        "        portfolio.iloc[0]['trade_action'] = 0\n",
        "        portfolio.iloc[0]['qty_onhand'] = 0\n",
        "        portfolio.iloc[0]['cost_basis'] = 0.00\n",
        "        portfolio.iloc[0]['sold_transaction'] = 0.00\n",
        "        portfolio.iloc[0]['gain_loss'] = 0.00\n",
        "        portfolio.iloc[0]['cash_onhand'] = initial_capital\n",
        "        portfolio.iloc[0]['position_value'] = 0.00\n",
        "        portfolio.iloc[0]['total_position'] = initial_capital\n",
        "        portfolio.iloc[0]['accumu_return'] = portfolio.iloc[0]['total_position'] - initial_capital\n",
        "        recent_cost = 0\n",
        "\n",
        "        # The conditional parameters below determine how the trading strategy will be carried out\n",
        "        for i in range(1, len(portfolio)):\n",
        "            if (trading_model.iloc[i]['entry_exit'] == 1) and (portfolio.iloc[i-1]['qty_onhand'] == 0):\n",
        "                portfolio.loc[i, 'trade_action'] = 1\n",
        "                portfolio.loc[i, 'qty_onhand'] = portfolio.iloc[i-1]['qty_onhand'] + portfolio.loc[i, 'trade_action']\n",
        "                portfolio.loc[i, 'cost_basis'] = trading_model.iloc[i]['open_price'] * portfolio.loc[i, 'trade_action']\n",
        "                portfolio.loc[i, 'sold_transaction'] = 0.00\n",
        "                portfolio.loc[i, 'gain_loss'] = 0.00\n",
        "                portfolio.loc[i, 'cash_onhand'] = portfolio.iloc[i-1]['cash_onhand'] - portfolio.loc[i, 'cost_basis']\n",
        "                recent_cost = trading_model.iloc[i]['open_price'] * portfolio.loc[i, 'trade_action']\n",
        "                if verbose: print('BOUGHT QTY:', portfolio.loc[i, 'trade_action'], 'on', portfolio.index[i], 'at the price of', trading_model.iloc[i]['open_price'])\n",
        "            elif (trading_model.iloc[i]['entry_exit'] == -1) and (portfolio.iloc[i-1]['qty_onhand'] > 0):\n",
        "                portfolio.loc[i, 'trade_action'] = -1\n",
        "                portfolio.loc[i, 'qty_onhand'] = portfolio.iloc[i-1]['qty_onhand'] + portfolio.loc[i, 'trade_action']\n",
        "                portfolio.loc[i, 'cost_basis'] = 0.00\n",
        "                portfolio.loc[i, 'sold_transaction'] = trading_model.iloc[i]['open_price'] * portfolio.loc[i, 'trade_action'] * -1\n",
        "                portfolio.loc[i, 'gain_loss'] = (recent_cost + (trading_model.iloc[i]['open_price'] * portfolio.loc[i, 'trade_action'])) * -1\n",
        "                portfolio.loc[i, 'cash_onhand'] = portfolio.iloc[i-1]['cash_onhand'] + portfolio.loc[i, 'sold_transaction']\n",
        "                recent_cost = 0.00\n",
        "                if verbose: print('SOLD QTY:', portfolio.loc[i, 'trade_action'], 'on', portfolio.index[i], 'at the price of', trading_model.iloc[i]['open_price'])\n",
        "            else:\n",
        "                portfolio.loc[i, 'trade_action'] = 0\n",
        "                portfolio.loc[i, 'qty_onhand'] = portfolio.iloc[i-1]['qty_onhand']\n",
        "                portfolio.loc[i, 'cost_basis'] = portfolio.iloc[i-1]['cost_basis']\n",
        "                portfolio.loc[i, 'sold_transaction'] = 0.00\n",
        "                portfolio.loc[i, 'gain_loss'] = 0.00\n",
        "                portfolio.loc[i, 'cash_onhand'] = portfolio.iloc[i-1]['cash_onhand']\n",
        "            portfolio.loc[i, 'position_value'] = trading_model.iloc[i]['close_price'] * portfolio.loc[i, 'qty_onhand']\n",
        "            portfolio.loc[i, 'total_position'] = portfolio.loc[i, 'cash_onhand'] + portfolio.loc[i, 'position_value']\n",
        "            portfolio.loc[i, 'accumu_return'] = portfolio.loc[i, 'total_position'] - initial_capital\n",
        "\n",
        "        return portfolio\n",
        "\n",
        "    portfolio_collection = {}\n",
        "\n",
        "    # Build dataframe for reporting model performance summary\n",
        "    performance_summary = pd.DataFrame(columns=['model_name', 'return_value', 'return_percent'])\n",
        "\n",
        "    for key in model_collection:\n",
        "        portfolio_collection[key] = trading_portfolio_generation(initial_capital, model_collection[key])\n",
        "        if initial_capital != 0:\n",
        "            return_percentage = portfolio_collection[key].accumu_return[-1] / initial_capital * 100\n",
        "        else:\n",
        "            return_percentage = None\n",
        "        performance_summary = performance_summary.append({'model_name': key, 'return_value': portfolio_collection[key].accumu_return[-1],\n",
        "                                                          'return_percent': return_percentage}, ignore_index=True)\n",
        "    print()\n",
        "\n",
        "    # Display the model performance summary\n",
        "    performance_summary.sort_values(by=['return_value'], inplace=True, ascending=False)\n",
        "    print(performance_summary)\n",
        "    print()\n",
        "\n",
        "    # Display the transactions from the top model\n",
        "    top_model = performance_summary.iloc[0]['model_name']\n",
        "    print(f'The transactions from the top model {top_model}:')\n",
        "    print(portfolio_collection[top_model][portfolio_collection[top_model].trade_action != 0])\n",
        "    print()\n",
        "\n",
        "    return portfolio_collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mVtz1MfHcb7"
      },
      "source": [
        "## Task 5. Evaluate Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JftMDKGkHiQA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def task5_evaluate_performance(stock_quandl, model_collection, portfolio_collection, initial_capital):\n",
        "    # Calculate the stock's performance for a long-only model\n",
        "    long_only_model = stock_quandl[model_start_date:model_end_date]\n",
        "    long_only_return = long_only_model.iloc[-1]['close'] - long_only_model.iloc[0]['open']\n",
        "    print('The performance of the long-only model from day one is: $%.2f' % long_only_return)\n",
        "    print()\n",
        "\n",
        "    best_model = ''\n",
        "    best_return = 0\n",
        "    for key in portfolio_collection:\n",
        "        if portfolio_collection[key]['accumu_return'][-1] > best_return:\n",
        "            best_model = key\n",
        "            best_return = portfolio_collection[best_model]['accumu_return'][-1]\n",
        "    print('The best model found is:', best_model)\n",
        "    print('The best profit/loss for the investing period is: $%.2f' % best_return)\n",
        "    if initial_capital != 0:\n",
        "        print('The best return percentage for initial capital is: %.2f%%' % (best_return / initial_capital * 100))\n",
        "    print()\n",
        "\n",
        "    worst_model = None\n",
        "    worst_return = long_only_return\n",
        "    for key in portfolio_collection:\n",
        "        if portfolio_collection[key]['accumu_return'][-1] < worst_return:\n",
        "            worst_model = key\n",
        "            worst_return = portfolio_collection[worst_model]['accumu_return'][-1]\n",
        "    print('The worst model found is:', worst_model)\n",
        "    print('The worst profit/loss for the investing period is: $%.2f' % worst_return)\n",
        "    if initial_capital != 0:\n",
        "        print('The worst return percentage for the initial capital is: %.2f%%' % (worst_return / initial_capital * 100))\n",
        "    print()\n",
        "\n",
        "    for key in model_collection:\n",
        "        print('Processing portfolio for model:', key)\n",
        "        trade_transactions = portfolio_collection[key][portfolio_collection[key].trade_action != 0]\n",
        "        print(trade_transactions)\n",
        "        print('Accumulated profit/loss for one share of stock with initial capital of $%.0f at the end of modeling period: $%.2f' % (initial_capital, portfolio_collection[key].accumu_return[-1]))\n",
        "        if initial_capital != 0:\n",
        "            return_percentage = portfolio_collection[key].accumu_return[-1] / initial_capital * 100\n",
        "            print('Accumulated return percentage based on the initial capital investment: %.2f%%' % return_percentage)\n",
        "        if trade_transactions.iloc[-1]['trade_action'] == 1:\n",
        "            print('The current status of the model is:', 'Holding a position since', trade_transactions.index.tolist()[-1], '\\n')\n",
        "        else:\n",
        "            print('The current status of the model is:', 'Waiting to enter since', trade_transactions.index.tolist()[-1], '\\n')\n",
        "\n",
        "# Example usage:\n",
        "# task5_evaluate_performance(stock_quandl, model_collection, portfolio_collection, initial_capital)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jr1K8w66pBrF"
      },
      "source": [
        "## Task Execution and Output Management"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMYGCvH0zkHe",
        "outputId": "f8f25c23-7c7d-48a9-cab9-90c551b2f330"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stocks to process: ['AAPL', 'ABBV', 'ABT', 'ADBE', 'AKAM', 'AMD', 'AMT', 'AMZN', 'ATVI', 'BNTX', 'BSX', 'BYND', 'CAG', 'CCI', 'CHGG', 'CHWY', 'CL', 'CLX', 'CMG', 'CNC', 'COR', 'COST', 'COUP', 'CPB', 'CRM', 'CRWD', 'CTXS', 'D', 'DDOG', 'DG', 'DHR', 'DOCU', 'DPZ', 'DXCM', 'EA', 'EBAY', 'EBS', 'EQIX', 'ETSY', 'EVBG', 'FSLY', 'GILD', 'GIS', 'GOLD', 'GOOG', 'HD', 'HRL', 'JNJ', 'KR', 'LLY', 'LOGI', 'LVGO', 'MASI', 'MDLZ', 'MKC', 'MKTX', 'MRNA', 'MRVL', 'MSFT', 'NEM', 'NET', 'NFLX', 'NVDA', 'OKTA', 'PANW', 'PEP', 'PFE', 'PG', 'PLD', 'PRGO', 'PTON', 'PYPL', 'REGN', 'RMD', 'RNG', 'SHOP', 'SJM', 'SNY', 'SPGI', 'SPLK', 'SPOT', 'SQ', 'TDOC', 'TGT', 'TMO', 'TTD', 'TTWO', 'TW', 'TWLO', 'UNH', 'VEEV', 'VMW', 'VZ', 'WING', 'WIX', 'WMT', 'WORK', 'ZM', 'ZS', 'ZTS']\n"
          ]
        }
      ],
      "source": [
        "dataset_path = 'https://www.dainesanalytics.com/datasets/cramer-covid19-index/Cramer_COVID-19_Index.csv'\n",
        "stock_meta = pd.read_csv(dataset_path, sep=',')\n",
        "stock_list = stock_meta['Symbol'].tolist()\n",
        "print('Stocks to process:', stock_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPBa7-ms43Q5"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "from datetime import datetime\n",
        "\n",
        "for stock_symbol in stock_list:\n",
        "    # Begin the timer for the script processing\n",
        "    startTimeModule = datetime.now()\n",
        "\n",
        "    print(f'Processing {stock_symbol} from {model_start_date.strftime(\"%Y-%m-%d\")} to {model_end_date.strftime(\"%Y-%m-%d\")}')\n",
        "\n",
        "    # Set up the redirection of output to a file\n",
        "    orig_stdout = sys.stdout\n",
        "    filename = f\"{gdrivePrefix}algotrading_{stock_symbol}_ema-crossover_{model_end_date.strftime('%Y%m%d')}.txt\"\n",
        "    f = open('algotrading_AAPL_ema-crossover_20200623.txt', 'w')\n",
        "    f = open('algotrading_AMZN_ema-crossover_20200623.txt', 'w')\n",
        "    f = open('algotrading_GOOG_ema-crossover_20200623.txt', 'w')\n",
        "    f = open('algotrading_NFLX_ema-crossover_20200623.txt', 'w')\n",
        "    sys.stdout = f\n",
        "\n",
        "    print(f'Processing the ticker symbol: {stock_symbol}')\n",
        "    print(f\"Starting date for the model: {model_start_date}\")\n",
        "    print(f\"Ending date for the model: {model_end_date}\")\n",
        "    print()\n",
        "\n",
        "try:\n",
        "    stock_prices = task2_acquire_process_data(stock_symbol, stock_start_date, model_end_date, quandl_key)\n",
        "    stock_models = task3_develop_strategy(stock_prices)\n",
        "    stock_portfolios = task4_back_test_model(stock_models, initial_capital)\n",
        "    task5_evaluate_performance(stock_prices, stock_models, stock_portfolios, initial_capital)\n",
        "except IndexError as e:\n",
        "    print(f\"IndexError: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "\n",
        "    sys.stdout = orig_stdout\n",
        "    f.close()\n",
        "\n",
        "    print(f'Total time for the script: {datetime.now() - startTimeModule}')\n",
        "    print(f'The output was stored in the file: {filename}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0pVOJDoIeqJ"
      },
      "outputs": [],
      "source": [
        "print ('Total time for the script:',(datetime.now() - startTimeScript))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}