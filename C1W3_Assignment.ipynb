{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SisekoC/My-Notebooks/blob/main/C1W3_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vVHPxs5m_bH"
      },
      "source": [
        "# Week 3 Assignment: Implement a Quadratic Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LsP_hkBm_bJ"
      },
      "source": [
        "In this week's programming exercise, you will build a custom quadratic layer which computes $y = ax^2 + bx + c$. Similar to the ungraded lab, this layer will be plugged into a model that will be trained on the MNIST dataset. Let's get started!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GE4f718m_bK"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qpUNODKWm_bK"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer\n",
        "\n",
        "import utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdHp_Vjwm_bL"
      },
      "source": [
        "### Define the quadratic layer (TODO)\n",
        "Implement a simple quadratic layer. It has 3 state variables: $a$, $b$ and $c$. The computation returned is $ax^2 + bx + c$. Make sure it can also accept an activation function.\n",
        "\n",
        "#### `__init__`\n",
        "- call `super(my_fun, self)` to access the base class of `my_fun`, and call the `__init__()` function to initialize that base class.  In this case, `my_fun` is `SimpleQuadratic` and its base class is `Layer`.\n",
        "- self.units: set this using one of the function parameters.\n",
        "- self.activation: The function parameter `activation` will be passed in as a string.  To get the tensorflow object associated with the string, please use `tf.keras.activations.get()`\n",
        "\n",
        "\n",
        "#### `build`\n",
        "The following are suggested steps for writing your code.  If you prefer to use fewer lines to implement it, feel free to do so.  Either way, you'll want to set `self.a`, `self.b` and `self.c`.\n",
        "\n",
        "- a_init: set this to tensorflow's `random_normal_initializer()`\n",
        "- a_init_val: Use the `random_normal_initializer()` that you just created and invoke it, setting the `shape` and `dtype`.\n",
        "    - The `shape` of `a` should have its row dimension equal to the last dimension of `input_shape`, and its column dimension equal to the number of units in the layer.  \n",
        "    - This is because you'll be matrix multiplying x^2 * a, so the dimensions should be compatible.\n",
        "    - set the dtype to 'float32'\n",
        "- self.a: create a tensor using tf.Variable, setting the initial_value and set trainable to True.\n",
        "\n",
        "- b_init, b_init_val, and self.b: these will be set in the same way that you implemented a_init, a_init_val and self.a\n",
        "- c_init: set this to `tf.zeros_initializer`.\n",
        "- c_init_val: Set this by calling the tf.zeros_initializer that you just instantiated, and set the `shape` and `dtype`\n",
        "  - shape: This will be a vector equal to the number of units.  This expects a tuple, and remember that a tuple `(9,)` includes a comma.\n",
        "  - dtype: set to 'float32'.\n",
        "- self.c: create a tensor using tf.Variable, and set the parameters `initial_value` and `trainable`.\n",
        "\n",
        "#### `call`\n",
        "The following section performs the multiplication x^2*a + x*b + c.  The steps are broken down for clarity, but you can also perform this calculation in fewer lines if you prefer.\n",
        "- x_squared: use tf.math.square()\n",
        "- x_squared_times_a: use tf.matmul().  \n",
        "  - If you see an error saying `InvalidArgumentError: Matrix size-incompatible`, please check the order of the matrix multiplication to make sure that the matrix dimensions line up.\n",
        "- x_times_b: use tf.matmul().\n",
        "- x2a_plus_xb_plus_c: add the three terms together.\n",
        "- activated_x2a_plus_xb_plus_c: apply the class's `activation` to the sum of the three terms.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "deletable": false,
        "id": "Ga20PttZFXm4",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "0df055c519bde80c488c22be89fdb8ef",
          "grade": false,
          "grade_id": "cell-c302ddc177c098f8",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# Please uncomment all lines in this cell and replace those marked with `# YOUR CODE HERE`.\n",
        "# You can select all lines in this code cell with Ctrl+A (Windows/Linux) or Cmd+A (Mac), then press Ctrl+/ (Windows/Linux) or Cmd+/ (Mac) to uncomment.\n",
        "\n",
        "\n",
        "\n",
        "class SimpleQuadratic(Layer):\n",
        "\n",
        "    def __init__(self, units=32, activation=None):\n",
        "        '''Initializes the class and sets up the internal variables'''\n",
        "        # YOUR CODE HERE\n",
        "        super(SimpleQuadratic, self).__init__()\n",
        "        self.units = units\n",
        "        self.activation = tf.keras.activations.get(activation)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        '''Create the state of the layer (weights)'''\n",
        "        # a and b should be initialized with random normal, c (or the bias) with zeros.\n",
        "        # remember to set these as trainable.\n",
        "        # YOUR CODE HERE\n",
        "        a_init = tf.random_normal_initializer()\n",
        "        b_init = tf.random_normal_initializer()\n",
        "        c_init = tf.zeros_initializer()\n",
        "\n",
        "        self.a = tf.Variable(name = \"kernel\", initial_value = a_init(shape= (input_shape[-1], self.units),\n",
        "                                                                    dtype= \"float32\"), trainable = True)\n",
        "\n",
        "        self.b = tf.Variable(name = \"kernel\", initial_value = b_init(shape= (input_shape[-1], self.units),\n",
        "                                                                    dtype= \"float32\"), trainable = True)\n",
        "\n",
        "        self.c = tf.Variable(name = \"bias\", initial_value = c_init(shape= (self.units,),\n",
        "                                                                    dtype= \"float32\"), trainable = True)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        '''Defines the computation from inputs to outputs'''\n",
        "        # YOUR CODE HERE\n",
        "        result = tf.matmul(tf.math.square(inputs), self.a) + tf.matmul(inputs, self.b) + self.c\n",
        "        return self.activation(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzQR2Ap6m_bM"
      },
      "source": [
        "Test your implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "0965bec4878a263cf06b286cd0fe3b2a",
          "grade": true,
          "grade_id": "cell-c3ebc4cccbb7f454",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxtYfJipm_bM",
        "outputId": "14540484-64f8-41a4-ab9c-4c64ceb1bcea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92m All public tests passed\n"
          ]
        }
      ],
      "source": [
        "utils.test_simple_quadratic(SimpleQuadratic)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgzbpImTm_bN"
      },
      "source": [
        "Train your model with the `SimpleQuadratic` layer that you just implemented."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14tl1CluExjJ",
        "outputId": "82a23124-8ac3-45a2-edcb-4de6a76a112b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.4583 - loss: 1.6464 - val_accuracy: 0.8931 - val_loss: 0.6229\n",
            "Epoch 2/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8150 - loss: 0.6623 - val_accuracy: 0.9383 - val_loss: 0.3003\n",
            "Epoch 3/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.8784 - loss: 0.4362 - val_accuracy: 0.9498 - val_loss: 0.2385\n",
            "Epoch 4/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9016 - loss: 0.3563 - val_accuracy: 0.9501 - val_loss: 0.2022\n",
            "Epoch 5/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9148 - loss: 0.3157 - val_accuracy: 0.9576 - val_loss: 0.1742\n",
            "Epoch 6/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9256 - loss: 0.2761 - val_accuracy: 0.9608 - val_loss: 0.1564\n",
            "Epoch 7/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9318 - loss: 0.2501 - val_accuracy: 0.9613 - val_loss: 0.1533\n",
            "Epoch 8/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.9346 - loss: 0.2373 - val_accuracy: 0.9613 - val_loss: 0.1428\n",
            "Epoch 9/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9377 - loss: 0.2284 - val_accuracy: 0.9648 - val_loss: 0.1503\n",
            "Epoch 10/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9401 - loss: 0.2187 - val_accuracy: 0.9674 - val_loss: 0.1304\n",
            "Epoch 11/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9442 - loss: 0.2049 - val_accuracy: 0.9705 - val_loss: 0.1179\n",
            "Epoch 12/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9474 - loss: 0.1911 - val_accuracy: 0.9659 - val_loss: 0.1277\n",
            "Epoch 13/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9490 - loss: 0.1885 - val_accuracy: 0.9712 - val_loss: 0.1121\n",
            "Epoch 14/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9492 - loss: 0.1867 - val_accuracy: 0.9733 - val_loss: 0.1089\n",
            "Epoch 15/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9507 - loss: 0.1755 - val_accuracy: 0.9708 - val_loss: 0.1086\n",
            "Epoch 16/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9529 - loss: 0.1668 - val_accuracy: 0.9683 - val_loss: 0.1140\n",
            "Epoch 17/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9528 - loss: 0.1688 - val_accuracy: 0.9732 - val_loss: 0.1157\n",
            "Epoch 18/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9556 - loss: 0.1619 - val_accuracy: 0.9706 - val_loss: 0.1078\n",
            "Epoch 19/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9574 - loss: 0.1585 - val_accuracy: 0.9752 - val_loss: 0.0998\n",
            "Epoch 20/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9557 - loss: 0.1614 - val_accuracy: 0.9730 - val_loss: 0.1005\n",
            "Epoch 21/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9567 - loss: 0.1579 - val_accuracy: 0.9740 - val_loss: 0.0965\n",
            "Epoch 22/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9569 - loss: 0.1572 - val_accuracy: 0.9728 - val_loss: 0.0993\n",
            "Epoch 23/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9607 - loss: 0.1426 - val_accuracy: 0.9711 - val_loss: 0.1025\n",
            "Epoch 24/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9609 - loss: 0.1427 - val_accuracy: 0.9748 - val_loss: 0.0967\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9701 - loss: 0.1106\n",
            "Test accuracy: 97.55%\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# SimpleQuadratic is a custom layer\n",
        "class SimpleQuadratic(tf.keras.layers.Layer):\n",
        "    def __init__(self, units=32, activation=None):\n",
        "        super(SimpleQuadratic, self).__init__()\n",
        "        self.units = units\n",
        "        self.activation = tf.keras.activations.get(activation)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        w_init = tf.random_normal_initializer()\n",
        "        b_init = tf.zeros_initializer()\n",
        "\n",
        "        self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
        "                                 initializer=w_init,\n",
        "                                 trainable=True,\n",
        "                                 name=\"kernel\")\n",
        "        self.b = self.add_weight(shape=(self.units,),\n",
        "                                 initializer=b_init,\n",
        "                                 trainable=True,\n",
        "                                 name=\"bias\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        squared_inputs = tf.square(inputs)\n",
        "        output = tf.matmul(squared_inputs, self.w) + self.b\n",
        "        if self.activation:\n",
        "            output = self.activation(output)\n",
        "        return output\n",
        "\n",
        "# Load data\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    SimpleQuadratic(128, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "    SimpleQuadratic(64, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "    SimpleQuadratic(32, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=50, validation_split=0.2, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy: {accuracy[1]*100:.2f}%')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_IxKw7Qm_bO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}